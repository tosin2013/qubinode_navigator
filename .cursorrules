# Qubinode Navigator Development Rules
# Auto-generated from AGENTS.md and ADR documentation
# Last updated: 2025-12-02

## Project Overview
Qubinode Navigator is an infrastructure automation platform combining:
- Airflow workflow orchestration (DAGs)
- AI Assistant (llama.cpp + IBM Granite)
- MCP Servers for LLM tool integration
- Plugin architecture for extensible deployments

## Code Style

### Python
- Follow PEP 8
- Use type hints
- DAGs: Follow ADR-0045 standards strictly
- Prefer f-strings over string concatenation

### Bash
- Use shellcheck compliance
- Prefer `[[` over `[` for conditionals
- Use `set -e` or `set -euo pipefail` for scripts
- Never use Unicode/emoji in bash commands

### DAG Development (ADR-0045 Critical Rules)
1. Use `"""` (triple double quotes) for bash_command, NEVER `'''`
2. NO string concatenation in bash_command
3. Use ASCII-only characters: `[OK]`, `[ERROR]`, `[WARN]`, `[INFO]`, `[SKIP]`
4. Use hardcoded paths or environment variables
5. DAG IDs must be snake_case matching filename
6. Always include `export PATH="/home/airflow/.local/bin:$PATH"` for kcli/ansible

### Log Prefixes (Required)
| Prefix | Meaning |
|--------|---------|
| [OK] | Success |
| [ERROR] | Error/Failure |
| [WARN] | Warning |
| [INFO] | Informational |
| [SKIP] | Skipped step |

## SSH Execution Pattern (ADR-0046)
For Ansible or host commands from Airflow containers, use SSH:
```python
bash_command="""
ssh -o StrictHostKeyChecking=no root@localhost \
    "cd /opt/kcli-pipelines && ./deploy.sh"
"""
```

## Testing Requirements
- Test kcli commands with airflow/scripts/test-*.sh first
- Validate DAG syntax: `python3 -c "import ast; ast.parse(open('dag.py').read())"`
- Use pre-flight checks before VM operations
- Validate Airflow imports before committing

## Commit Convention
- Prefix: feat|fix|docs|refactor|test|chore
- Reference ADRs when applicable
- Include test outputs with [OK]/[ERROR] prefixes
- Example: `feat(dag): Add keycloak deployment DAG (ADR-0047)`

## MCP Integration
- Always use preflight_vm_creation() before create_vm()
- Check DAG status with list_dags() before triggering
- Use search_similar_errors() for debugging

## Key Paths
| Purpose | Path |
|---------|------|
| DAGs | airflow/dags/ |
| Operators | airflow/plugins/qubinode/ |
| MCP Server | airflow/scripts/mcp_server_fastmcp.py |
| Scripts | airflow/scripts/, scripts/development/ |
| Config | config/, .env |
| ADRs | docs/adrs/ |

## Sensitive Files (Never Commit)
- `.env` - Contains credentials
- `config/vault.yml` - Vault tokens
- `*.pem`, `*.key` - Certificates/keys
- `pull-secret.json` - OpenShift pull secrets

## Container Runtime
- Use Podman as primary (Red Hat/CentOS/Fedora systems)
- Fall back to Docker if Podman unavailable

## Important ADRs
| ADR | Topic |
|-----|-------|
| ADR-0001 | Core architecture decisions |
| ADR-0036 | Airflow integration architecture |
| ADR-0045 | DAG development standards (CRITICAL) |
| ADR-0046 | Validation pipeline & host execution |
| ADR-0047 | kcli-pipelines integration |
| ADR-0055 | Zero-friction infrastructure services |

## Pre-commit Checklist for DAGs
- [ ] DAG file uses snake_case naming
- [ ] DAG ID matches filename
- [ ] Uses `"""` (double quotes) for bash_command
- [ ] No Unicode/emoji characters in bash commands
- [ ] No string concatenation in bash_command
- [ ] All paths are hardcoded or use environment variables
- [ ] Error handling uses simple exit codes
- [ ] Required volume mounts are documented
- [ ] Python syntax check passes
- [ ] Airflow import check passes

## Deployment Troubleshooting Protocol (SRE Mode)

When a user reports runtime/deployment errors, **ALWAYS prioritize environmental diagnostics over source code inspection**.

### Priority Order for Diagnosis
1. **System State First** - Check services, logs, resources before reading code
2. **Environment Over Code** - 90% of deployment issues are environmental
3. **Fix Environment, Not Scripts** - Do not refactor deploy scripts during troubleshooting

### Required Diagnostic Commands (Run These First)
```bash
# 1. Service Status
systemctl status libvirtd podman airflow-webserver

# 2. Recent System Errors
journalctl -p err --since "30 minutes ago" --no-pager | tail -30

# 3. Resource Availability
free -h && df -h / && df -h /var/lib/libvirt

# 4. Network/DNS
ping -c1 8.8.8.8 && nslookup $(hostname)

# 5. Container Status
podman ps -a | grep -E "(airflow|ai-assistant|mcp)"

# 6. Firewall Rules
firewall-cmd --list-all 2>/dev/null || iptables -L -n | head -20
```

### SRE Mode Rules
| Action | Allowed | Forbidden |
|--------|---------|-----------|
| Check journalctl/systemctl | ✓ | |
| Diagnose DNS/firewall/SELinux | ✓ | |
| Suggest dnf/yum install commands | ✓ | |
| Fix permissions/disk space | ✓ | |
| Propose GitHub Issues for bugs | ✓ | |
| Refactor deploy-qubinode.sh | | ✗ |
| Rewrite core Python files | | ✗ |
| Add new features during debug | | ✗ |

### Common Environmental Issues
| Symptom | Check First | NOT Code |
|---------|-------------|----------|
| "Connection refused" | firewall-cmd, systemctl | API code |
| "No such file" | ls -la, permissions | Path logic |
| "DNS resolution failed" | /etc/resolv.conf, nmcli | DNS code |
| "Out of memory" | free -h, dmesg | Memory handling |
| "Permission denied" | ls -la, SELinux context | Auth code |

### When to Switch to Developer Mode
Only after confirming:
- [ ] All services are running (`systemctl` checks pass)
- [ ] No resource constraints (memory, disk, CPU)
- [ ] Network/DNS resolves correctly
- [ ] No SELinux denials (`ausearch -m avc -ts recent`)
- [ ] User explicitly says "The system is running"
