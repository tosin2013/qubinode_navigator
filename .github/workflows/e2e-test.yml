# E2E Integration Test Workflow
# Per ADR-0067: Self-Hosted Runner E2E Testing with One-Shot Deployment
#
# This workflow deploys the complete Qubinode stack on a self-hosted runner
# and validates the Smart Pipeline (ADR-0066) with FreeIPA as test workload.
#
# IDEMPOTENT: Can be torn down and re-run cleanly

name: E2E Integration Test

on:
  schedule:
    - cron: '0 3 * * 0'  # Weekly Sunday 3am UTC
  workflow_dispatch:
    inputs:
      teardown_first:
        description: 'Teardown existing deployment before starting'
        type: boolean
        default: true
      deploy_freeipa:
        description: 'Deploy FreeIPA VM for full test'
        type: boolean
        default: true
      skip_cleanup:
        description: 'Skip cleanup after test (for debugging)'
        type: boolean
        default: false

env:
  # Deployment Configuration
  QUBINODE_DOMAIN: "e2e.qubinode.local"
  # Container names (podman-compose uses format: <project>_<service>_<instance>)
  # The airflow/ directory creates project "airflow", so scheduler is "airflow_airflow-scheduler_1"
  AIRFLOW_SCHEDULER_CONTAINER: "airflow_airflow-scheduler_1"
  QUBINODE_ADMIN_USER: "github-runner"
  QUBINODE_CLUSTER_NAME: "e2e-test"
  QUBINODE_DEPLOYMENT_MODE: "production"
  QUBINODE_ENABLE_AI_ASSISTANT: "true"
  QUBINODE_ENABLE_AIRFLOW: "true"
  BUILD_AI_ASSISTANT_FROM_SOURCE: "true"
  CICD_PIPELINE: "true"
  INVENTORY: "localhost"
  # Skip local model (llama.cpp + Granite) - use cloud APIs via PydanticAI orchestrator
  # This speeds up CI by avoiding 2-5 min model download
  USE_LOCAL_MODEL: "false"

jobs:
  e2e-test:
    name: E2E Integration Test
    runs-on: self-hosted
    timeout-minutes: 120

    steps:
      # =========================================================================
      # Phase 0: Checkout and Setup
      # =========================================================================
      - name: Clean workspace (fix root-owned files from previous run)
        run: |
          # Previous runs with sudo -E create root-owned files that the runner can't clean
          # This must run BEFORE checkout to avoid permission errors
          if [ -d "${{ github.workspace }}" ]; then
            echo "[INFO] Cleaning workspace from previous run..."
            sudo rm -rf "${{ github.workspace }}"/* "${{ github.workspace }}"/.[!.]* 2>/dev/null || true
            echo "[OK] Workspace cleaned"
          fi

      - name: Checkout code
        uses: actions/checkout@v6

      - name: Display runner info
        run: |
          echo "========================================"
          echo "E2E Integration Test"
          echo "========================================"
          echo "Runner: $(hostname)"
          echo "OS: $(cat /etc/os-release | grep PRETTY_NAME | cut -d'"' -f2)"
          echo "Kernel: $(uname -r)"
          echo "Date: $(date)"
          echo "========================================"

      # =========================================================================
      # Phase 1: Teardown previous deployment (always runs for clean state)
      # =========================================================================
      - name: Teardown existing deployment
        run: |
          echo "========================================"
          echo "Tearing down existing deployment"
          echo "========================================"

          # Stop and remove ALL podman containers (both user and root)
          echo "[INFO] Stopping all podman containers..."
          podman stop -a 2>/dev/null || true
          podman rm -a -f 2>/dev/null || true
          sudo podman stop -a 2>/dev/null || true
          sudo podman rm -a -f 2>/dev/null || true

          # Clean up podman networks
          echo "[INFO] Cleaning up podman networks..."
          podman network prune -f 2>/dev/null || true
          sudo podman network prune -f 2>/dev/null || true

          # Stop Airflow systemd services if running
          if systemctl is-active --quiet airflow-scheduler 2>/dev/null; then
            echo "[INFO] Stopping Airflow services..."
            sudo systemctl stop airflow-scheduler airflow-webserver 2>/dev/null || true
          fi

          # Stop podman-compose services in airflow directory
          echo "[INFO] Stopping podman-compose services..."
          cd ${{ github.workspace }}/airflow 2>/dev/null && sudo podman-compose down 2>/dev/null || true

          # Delete FreeIPA VM if exists (only if kcli/libvirt available)
          # NOTE: Must use sudo kcli to see VMs managed by root
          if command -v kcli &>/dev/null && [ -S /var/run/libvirt/libvirt-sock ]; then
            echo "[INFO] Checking for existing VMs..."
            sudo kcli list vm 2>/dev/null || true

            # Explicitly check and delete FreeIPA VM
            if sudo kcli list vm 2>/dev/null | grep -q "freeipa"; then
              echo "[INFO] Found existing FreeIPA VM - deleting..."
              sudo kcli delete vm freeipa -y 2>&1 || true
              # Wait a moment for deletion to complete
              sleep 5
              # Verify deletion
              if sudo kcli list vm 2>/dev/null | grep -q "freeipa"; then
                echo "[WARN] FreeIPA VM still exists after delete attempt"
                sudo kcli list vm 2>/dev/null | grep freeipa || true
              else
                echo "[OK] FreeIPA VM deleted successfully"
              fi
            else
              echo "[OK] No existing FreeIPA VM found"
            fi

            # Clean up any other test VMs
            echo "[INFO] Cleaning up other test VMs..."
            sudo kcli list vm 2>/dev/null | grep -iE "e2e|test" | awk '{print $2}' | while read vm; do
              if [ -n "$vm" ]; then
                echo "  Deleting: $vm"
                sudo kcli delete vm "$vm" -y 2>/dev/null || true
              fi
            done

            echo "[INFO] Final VM list:"
            sudo kcli list vm 2>/dev/null || true
          else
            echo "[INFO] Skipping VM cleanup (libvirt not available)"
          fi

          echo "[OK] Teardown complete"

      # =========================================================================
      # Phase 2: Deploy Infrastructure
      # =========================================================================
      - name: Login to Red Hat Registry
        env:
          REDHAT_USERNAME: ${{ secrets.REDHAT_USERNAME }}
          REDHAT_PASSWORD: ${{ secrets.REDHAT_PASSWORD }}
        run: |
          echo "[INFO] Logging into registry.redhat.io..."
          if [ -n "$REDHAT_USERNAME" ] && [ -n "$REDHAT_PASSWORD" ]; then
            # Login as root for privileged container builds
            sudo podman login registry.redhat.io -u "$REDHAT_USERNAME" -p "$REDHAT_PASSWORD"
            echo "[OK] Logged into Red Hat registry"
          else
            echo "[WARN] Red Hat registry credentials not configured, will use fallback image"
          fi

      - name: Setup Ansible vault password
        env:
          SSH_PASSWORD: ${{ secrets.SSH_PASSWORD }}
        run: |
          # Create vault password file for Ansible (referenced in ansible.cfg)
          VAULT_PASS="${SSH_PASSWORD:-defaultpassword}"
          echo "$VAULT_PASS" > "${{ github.workspace }}/.vault_password"
          chmod 600 "${{ github.workspace }}/.vault_password"
          # Also create in home directories for scripts that look there
          echo "$VAULT_PASS" > "$HOME/.vault_password"
          chmod 600 "$HOME/.vault_password"
          # Create in admin user's home (may be different from current user when using sudo)
          ADMIN_HOME=$(getent passwd "$QUBINODE_ADMIN_USER" | cut -d: -f6 || echo "/home/$QUBINODE_ADMIN_USER")
          if [ -d "$ADMIN_HOME" ] && [ "$ADMIN_HOME" != "$HOME" ]; then
            sudo sh -c "echo '$VAULT_PASS' > '$ADMIN_HOME/.vault_password' && chmod 600 '$ADMIN_HOME/.vault_password' && chown $QUBINODE_ADMIN_USER '$ADMIN_HOME/.vault_password'"
          fi
          # Also create for root if running privileged operations
          sudo sh -c "echo '$VAULT_PASS' > /root/.vault_password && chmod 600 /root/.vault_password"
          echo "[OK] Vault password files created"

      - name: Configure SSH for Airflow container host access
        run: |
          # ADR-0043/ADR-0046: Airflow containers SSH to localhost to run kcli
          # The container needs SSH access to the host for kcli operations
          echo "========================================"
          echo "Configuring SSH for Airflow container"
          echo "========================================"

          # Determine admin user's home directory
          SSH_USER="${QUBINODE_ADMIN_USER:-root}"
          if [ "$SSH_USER" = "root" ]; then
            SSH_HOME="/root"
          else
            SSH_HOME=$(getent passwd "$SSH_USER" | cut -d: -f6 || echo "/home/$SSH_USER")
          fi
          echo "[INFO] Configuring SSH for user: $SSH_USER (home: $SSH_HOME)"

          # Ensure .ssh directory exists for the admin user
          sudo mkdir -p "$SSH_HOME/.ssh"
          sudo chmod 700 "$SSH_HOME/.ssh"
          sudo chown "$SSH_USER:$SSH_USER" "$SSH_HOME/.ssh" 2>/dev/null || true

          # Ensure SSH key exists for admin user
          if ! sudo test -f "$SSH_HOME/.ssh/id_rsa"; then
            echo "[INFO] Generating SSH key for $SSH_USER..."
            sudo ssh-keygen -t rsa -b 4096 -f "$SSH_HOME/.ssh/id_rsa" -N '' -q
            sudo chown "$SSH_USER:$SSH_USER" "$SSH_HOME/.ssh/id_rsa" "$SSH_HOME/.ssh/id_rsa.pub" 2>/dev/null || true
          fi
          echo "[OK] SSH key exists: $SSH_HOME/.ssh/id_rsa"

          # Ensure authorized_keys file exists
          sudo touch "$SSH_HOME/.ssh/authorized_keys"
          sudo chmod 600 "$SSH_HOME/.ssh/authorized_keys"
          sudo chown "$SSH_USER:$SSH_USER" "$SSH_HOME/.ssh/authorized_keys" 2>/dev/null || true

          # Add the key to authorized_keys for localhost access
          # This allows the Airflow container to SSH to $SSH_USER@localhost
          USER_PUB_KEY=$(sudo cat "$SSH_HOME/.ssh/id_rsa.pub")
          if ! sudo grep -qF "$USER_PUB_KEY" "$SSH_HOME/.ssh/authorized_keys" 2>/dev/null; then
            echo "[INFO] Adding SSH key to authorized_keys for localhost access..."
            echo "$USER_PUB_KEY" | sudo tee -a "$SSH_HOME/.ssh/authorized_keys" > /dev/null
            echo "[OK] SSH key added to authorized_keys"
          else
            echo "[OK] SSH key already in authorized_keys"
          fi

          # Ensure SSH service is running
          if ! systemctl is-active --quiet sshd; then
            echo "[INFO] Starting SSH service..."
            sudo systemctl start sshd
            sudo systemctl enable sshd
          fi
          echo "[OK] SSH service is running"

          # Test SSH access to localhost
          echo "[INFO] Testing SSH access to $SSH_USER@localhost..."
          if sudo -u "$SSH_USER" ssh -o StrictHostKeyChecking=no -o BatchMode=yes -o ConnectTimeout=5 "$SSH_USER@localhost" "echo 'SSH localhost access verified'" 2>/dev/null || \
             sudo ssh -i "$SSH_HOME/.ssh/id_rsa" -o StrictHostKeyChecking=no -o BatchMode=yes -o ConnectTimeout=5 "$SSH_USER@localhost" "echo 'SSH localhost access verified'"; then
            echo "[OK] SSH localhost access works"
          else
            echo "[WARN] SSH localhost test failed - checking configuration"
            # Show some debug info
            echo "  authorized_keys fingerprints:"
            sudo ssh-keygen -lf "$SSH_HOME/.ssh/authorized_keys" 2>/dev/null | head -3 || echo "  (none)"
            echo "  id_rsa.pub fingerprint:"
            sudo ssh-keygen -lf "$SSH_HOME/.ssh/id_rsa.pub" 2>/dev/null || echo "  (none)"
          fi

          # Export SSH_USER for subsequent steps that may need it
          echo "SSH_USER=$SSH_USER" >> $GITHUB_ENV
          echo "SSH_HOME=$SSH_HOME" >> $GITHUB_ENV

          # CRITICAL: Copy SSH key to /root/.ssh/ for Airflow container access
          # The docker-compose.yml mounts /root/.ssh:/root/.ssh:ro into containers
          # So the key MUST be available at /root/.ssh/id_rsa for the container to use it
          if [ "$SSH_USER" != "root" ]; then
            echo "[INFO] Syncing SSH key to /root/.ssh for Airflow container access..."
            sudo mkdir -p /root/.ssh
            sudo chmod 700 /root/.ssh

            # Check if source key exists before copying
            if sudo test -f "$SSH_HOME/.ssh/id_rsa"; then
              # Only copy if /root/.ssh/id_rsa doesn't exist or is different
              if ! sudo test -f /root/.ssh/id_rsa || \
                 ! sudo diff -q "$SSH_HOME/.ssh/id_rsa" /root/.ssh/id_rsa >/dev/null 2>&1; then
                sudo cp "$SSH_HOME/.ssh/id_rsa" /root/.ssh/id_rsa
                sudo cp "$SSH_HOME/.ssh/id_rsa.pub" /root/.ssh/id_rsa.pub
                sudo chmod 600 /root/.ssh/id_rsa
                sudo chmod 644 /root/.ssh/id_rsa.pub
                echo "[OK] SSH key copied to /root/.ssh/"
              else
                echo "[OK] SSH key already in sync at /root/.ssh/"
              fi

              # Also add the key to root's authorized_keys for container->host SSH
              sudo touch /root/.ssh/authorized_keys
              sudo chmod 600 /root/.ssh/authorized_keys
              if ! sudo grep -qF "$USER_PUB_KEY" /root/.ssh/authorized_keys 2>/dev/null; then
                echo "$USER_PUB_KEY" | sudo tee -a /root/.ssh/authorized_keys > /dev/null
                echo "[OK] SSH key added to /root/.ssh/authorized_keys"
              fi
            else
              echo "[WARN] Source SSH key not found at $SSH_HOME/.ssh/id_rsa"
            fi
          fi

      - name: Deploy Qubinode Stack
        env:
          SSH_PASSWORD: ${{ secrets.SSH_PASSWORD }}
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
          MANAGER_MODEL: ${{ secrets.MANAGER_MODEL }}
          DEVELOPER_MODEL: ${{ secrets.DEVELOPER_MODEL }}
          PYDANTICAI_MODEL: ${{ secrets.PYDANTICAI_MODEL }}
          QUBINODE_DOMAIN: ${{ env.QUBINODE_DOMAIN }}
          QUBINODE_ADMIN_USER: ${{ env.QUBINODE_ADMIN_USER }}
          QUBINODE_CLUSTER_NAME: ${{ env.QUBINODE_CLUSTER_NAME }}
          QUBINODE_DEPLOYMENT_MODE: ${{ env.QUBINODE_DEPLOYMENT_MODE }}
          QUBINODE_ENABLE_AI_ASSISTANT: ${{ env.QUBINODE_ENABLE_AI_ASSISTANT }}
          QUBINODE_ENABLE_AIRFLOW: ${{ env.QUBINODE_ENABLE_AIRFLOW }}
          BUILD_AI_ASSISTANT_FROM_SOURCE: ${{ env.BUILD_AI_ASSISTANT_FROM_SOURCE }}
          CICD_PIPELINE: ${{ env.CICD_PIPELINE }}
          INVENTORY: ${{ env.INVENTORY }}
        run: |
          echo "========================================"
          echo "Deploying Qubinode Stack"
          echo "========================================"

          # Create required directories with proper permissions
          sudo mkdir -p ai-assistant/data
          sudo chmod 777 ai-assistant/data

          # Run the one-shot deployment script as root with environment preserved
          cd ${{ github.workspace }}
          chmod +x scripts/development/deploy-qubinode.sh
          sudo -E ./scripts/development/deploy-qubinode.sh || {
            echo ""
            echo "========================================"
            echo "Deployment failed - checking container status"
            echo "========================================"
            sudo podman ps -a
            echo ""
            echo "Container logs:"
            sudo podman logs qubinode-ai-assistant 2>&1 | tail -100 || true
            exit 1
          }

          echo "[OK] Qubinode stack deployed"

      - name: Wait for services to be ready
        run: |
          echo "========================================"
          echo "Waiting for services to be ready"
          echo "========================================"

          # AI Assistant model download can take 2-5 minutes
          # Use podman health status instead of just curl
          MAX_WAIT=360  # 6 minutes
          CHECK_INTERVAL=5
          ELAPSED=0

          echo "[INFO] Waiting for AI Assistant (model download may take 2-5 minutes)..."

          while [ $ELAPSED -lt $MAX_WAIT ]; do
            # Check if container is still running
            if ! sudo podman ps --format "{{.Names}}" 2>/dev/null | grep -q "^qubinode-ai-assistant$"; then
              echo "[ERROR] Container stopped running"
              sudo podman logs qubinode-ai-assistant 2>&1 | tail -50 || true
              exit 1
            fi

            # Get container health status via podman inspect
            HEALTH_STATUS=$(sudo podman inspect --format='{{.State.Health.Status}}' qubinode-ai-assistant 2>/dev/null || echo "unknown")

            case "$HEALTH_STATUS" in
              "healthy")
                echo "[OK] Container health check passed after ${ELAPSED}s"
                # Verify orchestrator endpoint
                ORCH_STATUS=$(curl -s http://localhost:8080/orchestrator/status 2>/dev/null || echo '{}')
                if echo "$ORCH_STATUS" | grep -q '"available"'; then
                  echo "[OK] Orchestrator is available"
                  echo "$ORCH_STATUS" | jq -c '{available, api_keys: .api_keys_configured}' 2>/dev/null || true
                  break 2  # Exit both case and while
                else
                  echo "[WARN] Health OK but orchestrator not available - checking logs..."
                  sudo podman logs qubinode-ai-assistant 2>&1 | grep -v "GET /\|POST /" | tail -20 || true
                fi
                ;;
              "starting")
                # Show progress every 30 seconds
                if [ $((ELAPSED % 30)) -eq 0 ] && [ $ELAPSED -gt 0 ]; then
                  echo "[INFO] Container starting... (${ELAPSED}s elapsed)"
                  sudo podman logs qubinode-ai-assistant 2>&1 | grep -i "download progress\|downloading" | tail -1 || true
                fi
                ;;
              "unhealthy")
                echo "[ERROR] Container health check failed"
                sudo podman logs qubinode-ai-assistant 2>&1 | tail -100 || true
                exit 1
                ;;
              *)
                # No health status yet - try endpoint directly
                HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:8080/health 2>/dev/null || echo "000")
                if [ "$HTTP_CODE" = "200" ]; then
                  echo "[OK] Health endpoint responding (HTTP 200)"
                  ORCH_STATUS=$(curl -s http://localhost:8080/orchestrator/status 2>/dev/null || echo '{}')
                  if echo "$ORCH_STATUS" | grep -q '"available"'; then
                    echo "[OK] Orchestrator ready"
                    break 2
                  fi
                fi
                ;;
            esac

            sleep $CHECK_INTERVAL
            ELAPSED=$((ELAPSED + CHECK_INTERVAL))
          done

          # Check if we exited the loop due to timeout
          if [ $ELAPSED -ge $MAX_WAIT ]; then
            echo ""
            echo "[ERROR] AI Assistant failed to start after ${MAX_WAIT}s"
            echo ""
            echo "=== CONTAINER STATUS ==="
            sudo podman inspect --format='Status: {{.State.Status}}, Health: {{.State.Health.Status}}' qubinode-ai-assistant 2>/dev/null || true
            echo ""
            echo "=== ERROR LOGS ==="
            sudo podman logs qubinode-ai-assistant 2>&1 | grep -iE "(error|exception|traceback|failed|cannot)" | head -30 || true
            echo ""
            echo "=== FULL STARTUP LOGS ==="
            sudo podman logs qubinode-ai-assistant 2>&1 | grep -v "GET /\|POST /" | head -100 || true
            exit 1
          fi

          # Wait for Airflow
          echo ""
          echo "[INFO] Waiting for Airflow..."
          for i in {1..30}; do
            if curl -s http://localhost:8888/health | grep -q "healthy"; then
              echo "[OK] Airflow is ready"
              break
            fi
            echo "  Attempt $i/30..."
            sleep 10
          done

          echo ""
          echo "[OK] All services ready"

      # =========================================================================
      # Phase 3: Validate Services (before FreeIPA deployment)
      # =========================================================================
      - name: Validate AI Assistant
        run: |
          echo "========================================"
          echo "Validating AI Assistant"
          echo "========================================"

          # Health check
          echo "[INFO] Health check..."
          curl -s http://localhost:8080/health | jq . || curl -s http://localhost:8080/health

          # Check models configured
          echo ""
          echo "[INFO] Model configuration..."
          curl -s http://localhost:8080/models 2>/dev/null | jq . || echo "Models endpoint not available"

          echo ""
          echo "[OK] AI Assistant validation complete"

      - name: Wait for Airflow Scheduler
        run: |
          echo "========================================"
          echo "Waiting for Airflow Scheduler to be ready"
          echo "========================================"

          MAX_ATTEMPTS=30
          ATTEMPT=0

          while [ $ATTEMPT -lt $MAX_ATTEMPTS ]; do
            ATTEMPT=$((ATTEMPT + 1))

            # Check if scheduler container is running and healthy
            if sudo podman exec $AIRFLOW_SCHEDULER_CONTAINER airflow dags list &>/dev/null; then
              echo "[OK] Airflow scheduler is ready (attempt $ATTEMPT/$MAX_ATTEMPTS)"
              break
            fi

            echo "[INFO] Waiting for scheduler... (attempt $ATTEMPT/$MAX_ATTEMPTS)"
            sleep 10
          done

          if [ $ATTEMPT -ge $MAX_ATTEMPTS ]; then
            echo "[WARN] Scheduler may not be fully ready, continuing anyway..."
          fi

      - name: Create localhost_ssh Airflow connection
        run: |
          echo "========================================"
          echo "Creating localhost_ssh Airflow connection"
          echo "========================================"

          # Determine SSH user (same logic as Configure SSH step)
          SSH_USER="${QUBINODE_ADMIN_USER:-root}"
          if [ "$SSH_USER" = "root" ]; then
            SSH_HOME="/root"
          else
            SSH_HOME=$(getent passwd "$SSH_USER" | cut -d: -f6 || echo "/home/$SSH_USER")
          fi
          SSH_KEY_PATH="$SSH_HOME/.ssh/id_rsa"

          echo "[INFO] Creating connection for SSH user: $SSH_USER"
          echo "[INFO] SSH key path: $SSH_KEY_PATH"

          # Delete existing connection if present (idempotent)
          sudo podman exec $AIRFLOW_SCHEDULER_CONTAINER \
            airflow connections delete localhost_ssh 2>/dev/null || true

          # Create the localhost_ssh connection
          sudo podman exec $AIRFLOW_SCHEDULER_CONTAINER \
            airflow connections add 'localhost_ssh' \
              --conn-type 'ssh' \
              --conn-host 'localhost' \
              --conn-login "$SSH_USER" \
              --conn-extra "{\"key_file\": \"$SSH_KEY_PATH\", \"no_host_key_check\": true}"

          # Verify connection was created
          echo ""
          echo "[INFO] Verifying connection..."
          sudo podman exec $AIRFLOW_SCHEDULER_CONTAINER \
            airflow connections get localhost_ssh 2>/dev/null && echo "[OK] Connection created" || {
              echo "[ERROR] Failed to create localhost_ssh connection"
              exit 1
            }

          # Test the SSH connection
          echo ""
          echo "[INFO] Testing SSH connectivity..."
          sudo podman exec $AIRFLOW_SCHEDULER_CONTAINER \
            ssh -o StrictHostKeyChecking=no -o BatchMode=yes -o ConnectTimeout=5 \
            "$SSH_USER@localhost" "echo '[OK] SSH connection works'" || {
              echo "[WARN] SSH test failed - DAGs may fail"
            }

      - name: Validate Airflow DAGs
        run: |
          echo "========================================"
          echo "Validating Airflow DAGs"
          echo "========================================"

          # List DAGs via podman exec (airflow CLI is inside the container)
          echo "[INFO] Available DAGs:"
          sudo podman exec $AIRFLOW_SCHEDULER_CONTAINER airflow dags list 2>/dev/null || {
            # Fallback: Use the AI Assistant's orchestrator which has DAG discovery
            echo "[INFO] Using AI Assistant orchestrator for DAG list..."
            curl -s http://localhost:8080/orchestrator/dags | jq -r '.dags[].dag_id // .dags[]' 2>/dev/null || echo "Could not list DAGs"
          }

          # Check for import errors via podman exec
          echo ""
          echo "[INFO] DAG import errors:"
          sudo podman exec $AIRFLOW_SCHEDULER_CONTAINER airflow dags list-import-errors 2>/dev/null || echo "[INFO] Import errors check skipped"

          echo ""
          echo "[OK] Airflow validation complete"

      # =========================================================================
      # Phase 4: Deploy FreeIPA VM via PydanticAI Smart Pipeline (ADR-0066)
      # =========================================================================
      - name: Orchestrator Intent Smoke Test (Dry Run)
        run: |
          echo "========================================"
          echo "Orchestrator Intent Smoke Test"
          echo "========================================"
          echo "[INFO] Testing orchestrator intent parsing without execution"
          echo ""

          # Test 1: Verify orchestrator status
          echo "=== Test 1: Orchestrator Status ==="
          ORCH_STATUS=$(curl -s http://localhost:8080/orchestrator/status 2>/dev/null)
          if echo "$ORCH_STATUS" | jq -e '.available == true' &>/dev/null; then
            echo "[OK] Orchestrator is available"
            echo "$ORCH_STATUS" | jq -c '{available, dag_count: .dag_count, api_keys: .api_keys_configured}' 2>/dev/null || true
          else
            echo "[WARN] Orchestrator not available - skipping intent tests"
            exit 0
          fi

          # Test 2: DAG Discovery
          echo ""
          echo "=== Test 2: DAG Discovery ==="
          DAGS=$(curl -s http://localhost:8080/orchestrator/dags 2>/dev/null)
          FREEIPA_FOUND=$(echo "$DAGS" | jq -r '.dags[] | select(.dag_id == "freeipa_deployment") | .dag_id' 2>/dev/null)
          if [ "$FREEIPA_FOUND" = "freeipa_deployment" ]; then
            echo "[OK] freeipa_deployment DAG discovered by orchestrator"
          else
            echo "[WARN] freeipa_deployment not in orchestrator DAG list"
            echo "Available DAGs:"
            echo "$DAGS" | jq -r '.dags[].dag_id' 2>/dev/null | head -10
          fi

          # Test 3: Intent Parsing (dry run - no execution)
          echo ""
          echo "=== Test 3: Intent Parsing (Dry Run) ==="
          echo "[INFO] Sending intent without auto_execute to test parsing..."

          INTENT_RESPONSE=$(curl -s -X POST http://localhost:8080/orchestrator/intent \
            -H "Content-Type: application/json" \
            -d '{
              "intent": "Deploy a FreeIPA identity management server",
              "params": {
                "vm_name": "freeipa-test",
                "action": "create"
              },
              "auto_approve": false,
              "auto_execute": false
            }' 2>/dev/null)

          echo "Intent Response:"
          echo "$INTENT_RESPONSE" | jq . 2>/dev/null || echo "$INTENT_RESPONSE"

          # Validate response
          MATCHED_DAG=$(echo "$INTENT_RESPONSE" | jq -r '.dag_id // .matched_dag // empty' 2>/dev/null)
          if [ "$MATCHED_DAG" = "freeipa_deployment" ]; then
            echo ""
            echo "[OK] Orchestrator correctly matched intent to freeipa_deployment DAG"
          elif [ -n "$MATCHED_DAG" ]; then
            echo ""
            echo "[WARN] Orchestrator matched to different DAG: $MATCHED_DAG"
          else
            echo ""
            echo "[INFO] Intent parsing response (may need approval or different format)"
          fi

          # Test 4: Validate DAG info endpoint
          echo ""
          echo "=== Test 4: DAG Info Endpoint ==="
          DAG_INFO=$(curl -s "http://localhost:8080/orchestrator/dags/freeipa_deployment" 2>/dev/null)
          if echo "$DAG_INFO" | jq -e '.dag_id' &>/dev/null; then
            echo "[OK] DAG info endpoint working"
            echo "$DAG_INFO" | jq -c '{dag_id, description, tags}' 2>/dev/null || true
          else
            echo "[INFO] DAG info endpoint returned: $(echo "$DAG_INFO" | head -c 100)"
          fi

          echo ""
          echo "========================================"
          echo "[OK] Orchestrator Intent Smoke Test Complete"
          echo "========================================"

      - name: Unpause FreeIPA DAG
        if: ${{ github.event.inputs.deploy_freeipa == 'true' || github.event_name == 'schedule' }}
        run: |
          echo "========================================"
          echo "Unpausing freeipa_deployment DAG"
          echo "========================================"

          # DAGs are paused by default (AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true)
          # We need to unpause before triggering
          echo "[INFO] Current DAG status:"
          sudo podman exec $AIRFLOW_SCHEDULER_CONTAINER airflow dags list -o table 2>/dev/null | grep -E "dag_id|freeipa" || true

          echo ""
          echo "[INFO] Unpausing freeipa_deployment DAG..."
          sudo podman exec $AIRFLOW_SCHEDULER_CONTAINER airflow dags unpause freeipa_deployment 2>&1 || {
            echo "[WARN] Could not unpause DAG - it may not exist yet"
          }

          echo ""
          echo "[INFO] DAG status after unpause:"
          sudo podman exec $AIRFLOW_SCHEDULER_CONTAINER airflow dags list -o table 2>/dev/null | grep -E "dag_id|freeipa" || true

      - name: Deploy FreeIPA via AI Assistant Orchestrator
        if: ${{ github.event.inputs.deploy_freeipa == 'true' || github.event_name == 'schedule' }}
        run: |
          echo "========================================"
          echo "Deploying FreeIPA via PydanticAI Smart Pipeline"
          echo "========================================"

          # Check if FreeIPA already exists
          if sudo kcli info vm freeipa 2>/dev/null | grep -q "status: up"; then
            echo "[OK] FreeIPA VM already running"
            sudo kcli info vm freeipa
            exit 0
          fi

          # Verify AI Assistant orchestrator is available and properly configured
          echo "[INFO] Checking AI Assistant Orchestrator status..."
          ORCHESTRATOR_STATUS=$(curl -s http://localhost:8080/orchestrator/status 2>/dev/null)
          echo "$ORCHESTRATOR_STATUS" | jq . 2>/dev/null || echo "$ORCHESTRATOR_STATUS"

          if ! echo "$ORCHESTRATOR_STATUS" | jq -e '.available == true' &>/dev/null; then
            echo "[ERROR] AI Assistant Orchestrator not available"
            echo "[INFO] The PydanticAI orchestrator is required for intent-based deployments (ADR-0066)"
            exit 1
          fi
          echo "[OK] Orchestrator is available"

          # Check if API keys are configured
          API_KEYS_OK=$(echo "$ORCHESTRATOR_STATUS" | jq -r '.api_keys_configured | to_entries | map(select(.value == true)) | length')
          if [ "$API_KEYS_OK" = "0" ]; then
            echo "[ERROR] No AI API keys configured in orchestrator"
            echo "[INFO] Ensure OPENROUTER_API_KEY is passed to the AI Assistant container"
            echo "[INFO] Check: api_keys_configured shows all false"
            exit 1
          fi
          echo "[OK] API keys configured: $API_KEYS_OK provider(s)"

          # Check DAG discovery
          echo "[INFO] Checking DAG discovery..."
          DAGS_COUNT=$(curl -s http://localhost:8080/orchestrator/dags | jq '.total')
          if [ "$DAGS_COUNT" = "0" ] || [ -z "$DAGS_COUNT" ]; then
            echo "[ERROR] No DAGs discovered by orchestrator"
            echo "[INFO] Ensure airflow/dags is mounted at /app/airflow/dags in the container"
            exit 1
          fi
          echo "[OK] Discovered $DAGS_COUNT DAGs"

          # Trigger FreeIPA deployment via AI Assistant Orchestrator (ADR-0066)
          # Using /orchestrator/intent endpoint for intent-based execution:
          # 1. Analyze the intent with PydanticAI Manager Agent
          # 2. Find/validate the appropriate DAG (freeipa_deployment)
          # 3. Execute via Airflow
          # 4. Monitor for shadow errors
          echo ""
          echo "[INFO] Sending request to AI Assistant Orchestrator..."
          echo "[INFO] Using /orchestrator/intent endpoint (intent-based execution)"

          RESPONSE=$(curl -s -X POST http://localhost:8080/orchestrator/intent \
            -H "Content-Type: application/json" \
            -d '{
              "intent": "Deploy FreeIPA server for E2E testing",
              "params": {
                "vm_name": "freeipa",
                "action": "create"
              },
              "auto_approve": true,
              "auto_execute": true
            }')

          echo ""
          echo "Orchestrator Response:"
          echo "$RESPONSE" | jq . 2>/dev/null || echo "$RESPONSE"

          # Check for HTTP errors
          if echo "$RESPONSE" | jq -e '.detail' &>/dev/null; then
            echo ""
            echo "[ERROR] Orchestrator returned an error:"
            echo "$RESPONSE" | jq '.detail' 2>/dev/null
            exit 1
          fi

          # Extract flow_id for monitoring
          FLOW_ID=$(echo "$RESPONSE" | jq -r '.flow_id // empty')
          if [ -n "$FLOW_ID" ]; then
            echo ""
            echo "[INFO] Flow ID: $FLOW_ID"
            echo "[INFO] Status endpoint: /orchestrator/flows/$FLOW_ID/status"
          fi

          # Check execution status
          STATUS=$(echo "$RESPONSE" | jq -r '.status // empty')
          DAG_ID=$(echo "$RESPONSE" | jq -r '.dag_id // empty')

          echo ""
          echo "[INFO] Status: $STATUS"
          echo "[INFO] DAG ID: $DAG_ID"

          if [ "$STATUS" = "executing" ] || [ "$STATUS" = "in_progress" ]; then
            echo "[OK] FreeIPA deployment initiated via Smart Pipeline"
          elif [ "$STATUS" = "completed" ] || [ "$STATUS" = "success" ]; then
            echo "[OK] FreeIPA deployment completed"
          elif [ "$STATUS" = "failed" ]; then
            echo ""
            echo "[ERROR] Orchestrator returned failure:"
            echo "$RESPONSE" | jq '.error_message' 2>/dev/null
            echo ""
            echo "User Actions:"
            echo "$RESPONSE" | jq '.user_actions' 2>/dev/null
            echo ""
            echo "Escalation Context:"
            echo "$RESPONSE" | jq '.escalation_context' 2>/dev/null
            exit 1
          else
            echo "[WARN] Unexpected orchestrator status: $STATUS"
            # Don't fail - let the validation step check if FreeIPA actually deployed
          fi

      - name: Wait for FreeIPA to be ready
        if: ${{ github.event.inputs.deploy_freeipa == 'true' || github.event_name == 'schedule' }}
        run: |
          echo "========================================"
          echo "Waiting for FreeIPA VM"
          echo "========================================"

          MAX_ATTEMPTS=40
          ATTEMPT=0

          # First, check if the DAG is still running or has failed
          echo "[INFO] Checking Airflow DAG run status..."
          sudo podman exec $AIRFLOW_SCHEDULER_CONTAINER airflow dags list-runs -d freeipa_deployment --limit 1 2>/dev/null || true

          while [ $ATTEMPT -lt $MAX_ATTEMPTS ]; do
            ATTEMPT=$((ATTEMPT + 1))
            echo ""
            echo "Check $ATTEMPT/$MAX_ATTEMPTS..."

            # Every 5th attempt, use Observer Agent for comprehensive DAG status
            if [ $((ATTEMPT % 5)) -eq 0 ]; then
              echo "[INFO] Using Observer Agent for comprehensive DAG status..."

              # Try Observer API first (provides shadow error detection)
              # Note: This is a POST endpoint that finds the latest run
              OBSERVE_HTTP_CODE=""
              OBSERVE_RESPONSE=$(curl -s -X POST --max-time 15 \
                -w "\n__HTTP_CODE__%{http_code}" \
                "http://localhost:8080/orchestrator/observe?dag_id=freeipa_deployment" 2>/dev/null || echo "{}")

              # Extract HTTP code from response
              OBSERVE_HTTP_CODE=$(echo "$OBSERVE_RESPONSE" | grep "__HTTP_CODE__" | sed 's/__HTTP_CODE__//')
              OBSERVE_RESPONSE=$(echo "$OBSERVE_RESPONSE" | grep -v "__HTTP_CODE__")

              # Debug: Show raw response on first Observer call
              if [ $ATTEMPT -eq 5 ]; then
                echo "  [DEBUG] Observer HTTP code: $OBSERVE_HTTP_CODE"
                echo "  [DEBUG] Observer response preview: $(echo "$OBSERVE_RESPONSE" | head -c 200)"
              fi

              if echo "$OBSERVE_RESPONSE" | jq -e '.overall_status' > /dev/null 2>&1; then
                DAG_STATUS=$(echo "$OBSERVE_RESPONSE" | jq -r '.overall_status // "unknown"')
                PROGRESS=$(echo "$OBSERVE_RESPONSE" | jq -r '.progress_percent // 0')
                HAS_ERRORS=$(echo "$OBSERVE_RESPONSE" | jq -r '.has_errors // false')
                HAS_WARNINGS=$(echo "$OBSERVE_RESPONSE" | jq -r '.has_warnings // false')
                SUMMARY=$(echo "$OBSERVE_RESPONSE" | jq -r '.summary // ""')

                echo "  DAG Status: $DAG_STATUS"
                echo "  Progress: ${PROGRESS}%"
                echo "  Summary: $SUMMARY"

                # Show any concerns (shadow errors, warnings)
                if [ "$HAS_WARNINGS" = "true" ] || [ "$HAS_ERRORS" = "true" ]; then
                  echo ""
                  echo "  === Observer Concerns ==="
                  echo "$OBSERVE_RESPONSE" | jq -r '.concerns[] | "  [\(.level)] \(.message)"' 2>/dev/null || true
                fi

                # Show recommendations
                echo ""
                echo "  === Recommendations ==="
                echo "$OBSERVE_RESPONSE" | jq -r '.recommendations[]' 2>/dev/null | head -3 || true

                if [ "$DAG_STATUS" = "failed" ] || [ "$HAS_ERRORS" = "true" ]; then
                  echo ""
                  echo "[ERROR] freeipa_deployment DAG failed or has errors!"
                  echo ""
                  echo "=== Observer Detailed Report ==="
                  echo "$OBSERVE_RESPONSE" | jq -r '.detailed_message // empty' 2>/dev/null || true
                  echo ""
                  echo "=== Failed Task Details ==="
                  echo "$OBSERVE_RESPONSE" | jq '.failed_task_details' 2>/dev/null || true
                  exit 1
                fi
              else
                # Fallback to basic Airflow CLI check
                echo "  (Observer returned HTTP $OBSERVE_HTTP_CODE, using Airflow CLI)"
                if [ -n "$OBSERVE_RESPONSE" ] && [ "$OBSERVE_RESPONSE" != "{}" ]; then
                  echo "  [DEBUG] Observer error: $(echo "$OBSERVE_RESPONSE" | jq -c '.detail // .' 2>/dev/null | head -c 150)"
                fi
                DAG_STATUS=$(sudo podman exec $AIRFLOW_SCHEDULER_CONTAINER airflow dags list-runs -d freeipa_deployment --limit 1 -o json 2>/dev/null | jq -r '.[0].state // "unknown"' 2>/dev/null || echo "unknown")
                echo "  DAG status: $DAG_STATUS"

                if [ "$DAG_STATUS" = "failed" ]; then
                  echo ""
                  echo "[ERROR] freeipa_deployment DAG failed!"
                  echo ""
                  echo "=== Scheduler Logs (last 50 lines) ==="
                  sudo podman logs $AIRFLOW_SCHEDULER_CONTAINER 2>&1 | grep -i "freeipa\|error\|failed" | tail -50 || true
                  exit 1
                fi
              fi
            fi

            # List VMs to see what exists
            echo "[DEBUG] Current VMs:"
            sudo kcli list vm 2>/dev/null | head -5 || echo "  (no VMs or kcli error)"

            # Get FreeIPA IP
            FREEIPA_IP=$(sudo kcli info vm freeipa 2>/dev/null | grep 'ip:' | awk '{print $2}' | head -1)

            if [ -n "$FREEIPA_IP" ] && [ "$FREEIPA_IP" != "None" ]; then
              echo "[INFO] FreeIPA IP: $FREEIPA_IP"

              # Check if FreeIPA web UI is accessible
              if curl -sk --connect-timeout 5 "https://$FREEIPA_IP/ipa/ui/" | grep -q "IPA"; then
                echo ""
                echo "========================================"
                echo "[OK] FreeIPA is ready!"
                echo "========================================"
                echo "IP Address: $FREEIPA_IP"
                echo "Web UI: https://$FREEIPA_IP/ipa/ui/"
                echo "========================================"
                exit 0
              fi

              # Alternative: check SSH
              if nc -z -w5 "$FREEIPA_IP" 22 2>/dev/null; then
                echo "[INFO] FreeIPA SSH is accessible, checking services..."
                ssh -o StrictHostKeyChecking=no -o ConnectTimeout=5 root@$FREEIPA_IP \
                  "systemctl is-active ipa" 2>/dev/null && {
                    echo "[OK] FreeIPA IPA service is running"
                    exit 0
                  }
              fi
            else
              # VM doesn't exist yet - check if DAG created it
              if [ $ATTEMPT -eq 10 ]; then
                echo ""
                echo "[DEBUG] VM not found after 10 attempts, checking DAG tasks..."
                # Show the DAG run details using correct Airflow CLI commands
                sudo podman exec $AIRFLOW_SCHEDULER_CONTAINER bash -c '
                  echo "=== DAG Runs ==="
                  airflow dags list-runs -d freeipa_deployment --limit 3 2>/dev/null || echo "No runs found"

                  # Get the execution date from latest run (if any)
                  EXEC_DATE=$(airflow dags list-runs -d freeipa_deployment --limit 1 -o plain 2>/dev/null | tail -1 | awk "{print \$3}")

                  if [ -n "$EXEC_DATE" ]; then
                    echo ""
                    echo "=== Task States for run: $EXEC_DATE ==="
                    # states-for-dag-run shows all task states for a run (no task_id needed)
                    airflow tasks states-for-dag-run freeipa_deployment "$EXEC_DATE" 2>/dev/null || echo "Could not get task states"
                  else
                    echo ""
                    echo "[WARN] No DAG runs found - DAG may not have been triggered"
                    echo ""
                    echo "=== DAG Info ==="
                    airflow dags show freeipa_deployment 2>/dev/null || echo "DAG not found"
                  fi
                ' 2>/dev/null || true
              fi
            fi

            sleep 30
          done

          echo ""
          echo "[WARN] FreeIPA VM not ready after $MAX_ATTEMPTS attempts"
          echo ""
          echo "=== Final VM Status ==="
          sudo kcli list vm 2>/dev/null || echo "kcli list failed"
          echo ""
          echo "=== DAG Run Status ==="
          sudo podman exec $AIRFLOW_SCHEDULER_CONTAINER airflow dags list-runs -d freeipa_deployment --limit 3 2>/dev/null || true
          echo ""
          echo "=== Scheduler Logs (last 30 lines with errors) ==="
          sudo podman logs $AIRFLOW_SCHEDULER_CONTAINER 2>&1 | grep -iE "error|failed|exception" | tail -30 || true

      # =========================================================================
      # Phase 5: Validate FreeIPA Deployment
      # =========================================================================
      - name: Validate FreeIPA VM
        if: ${{ github.event.inputs.deploy_freeipa == 'true' || github.event_name == 'schedule' }}
        run: |
          echo "========================================"
          echo "Validating FreeIPA VM"
          echo "========================================"

          # Get VM info
          echo "[INFO] VM Status:"
          sudo kcli info vm freeipa 2>/dev/null || echo "FreeIPA VM not found"

          # Get IP
          FREEIPA_IP=$(sudo kcli info vm freeipa 2>/dev/null | grep 'ip:' | awk '{print $2}' | head -1)

          if [ -n "$FREEIPA_IP" ] && [ "$FREEIPA_IP" != "None" ]; then
            echo ""
            echo "[INFO] FreeIPA IP: $FREEIPA_IP"

            # Test DNS resolution
            echo ""
            echo "[INFO] Testing DNS..."
            dig @$FREEIPA_IP freeipa.${QUBINODE_DOMAIN} +short 2>/dev/null || echo "DNS query failed"

            # Test LDAP
            echo ""
            echo "[INFO] Testing LDAP port..."
            nc -z -w5 $FREEIPA_IP 389 && echo "[OK] LDAP port open" || echo "[WARN] LDAP port not accessible"

            # Test Kerberos
            echo ""
            echo "[INFO] Testing Kerberos port..."
            nc -z -w5 $FREEIPA_IP 88 && echo "[OK] Kerberos port open" || echo "[WARN] Kerberos port not accessible"
          fi

          echo ""
          echo "[OK] FreeIPA validation complete"

      # =========================================================================
      # Phase 6: Smart Pipeline Validation (ADR-0066)
      # =========================================================================
      - name: Check Shadow Errors
        continue-on-error: true
        run: |
          echo "========================================"
          echo "Checking Smart Pipeline Shadow Errors"
          echo "========================================"

          # Query shadow errors endpoint
          ERRORS=$(curl -s http://localhost:8080/orchestrator/shadow-errors 2>/dev/null || echo '{"error": "endpoint not available"}')

          echo "$ERRORS" | jq . 2>/dev/null || echo "$ERRORS"

          # Check if there are shadow failures
          if echo "$ERRORS" | jq -e '.total_shadow_failures > 0' 2>/dev/null; then
            echo ""
            echo "[WARN] Shadow errors detected - review above"
          else
            echo ""
            echo "[OK] No shadow errors detected"
          fi

      - name: Check OpenLineage/Marquez
        continue-on-error: true
        run: |
          echo "========================================"
          echo "Checking OpenLineage/Marquez"
          echo "========================================"

          # Check if Marquez is running
          if curl -s http://localhost:5001/api/v1/namespaces 2>/dev/null | jq . ; then
            echo ""
            echo "[OK] Marquez is accessible"

            # List jobs in qubinode namespace
            echo ""
            echo "[INFO] Jobs in qubinode namespace:"
            curl -s http://localhost:5001/api/v1/namespaces/qubinode/jobs 2>/dev/null | jq '.jobs[].name' 2>/dev/null || echo "No jobs found"
          else
            echo "[INFO] Marquez not running or not accessible"
          fi

      # =========================================================================
      # Phase 7: Summary
      # =========================================================================
      - name: Generate Test Summary
        run: |
          echo ""
          echo "========================================"
          echo "E2E Test Summary"
          echo "========================================"
          echo ""
          echo "Deployment Status:"
          echo "  - AI Assistant: $(curl -s http://localhost:8080/health | grep -q 'ok\|healthy' && echo '✅ Running' || echo '❌ Not running')"
          echo "  - Airflow: $(curl -s http://localhost:8888/health | grep -q 'healthy' && echo '✅ Running' || echo '❌ Not running')"

          FREEIPA_IP=$(sudo kcli info vm freeipa 2>/dev/null | grep 'ip:' | awk '{print $2}' | head -1)
          if [ -n "$FREEIPA_IP" ] && [ "$FREEIPA_IP" != "None" ]; then
            echo "  - FreeIPA VM: ✅ Running ($FREEIPA_IP)"
          else
            echo "  - FreeIPA VM: ❌ Not deployed or no IP"
          fi

          echo ""
          echo "Access URLs:"
          echo "  - AI Assistant: http://$(hostname):8080"
          echo "  - Airflow UI: http://$(hostname):8888"
          if [ -n "$FREEIPA_IP" ]; then
            echo "  - FreeIPA: https://$FREEIPA_IP"
          fi
          echo ""
          echo "========================================"

      # =========================================================================
      # Phase 8: Cleanup (always runs unless skipped)
      # =========================================================================
      - name: Cleanup test resources
        if: ${{ always() && github.event.inputs.skip_cleanup != 'true' }}
        run: |
          echo "========================================"
          echo "Cleaning up test resources"
          echo "========================================"

          # Always cleanup VMs after E2E test to avoid leaving resources
          # Skip only if the user explicitly sets skip_cleanup=true (for debugging)
          # NOTE: Must use sudo kcli to see/manage VMs created by root
          echo "[INFO] Deleting FreeIPA VM..."
          sudo kcli delete vm freeipa -y 2>/dev/null || true

          # Clean up any other test VMs that might have been created
          echo "[INFO] Cleaning up any lingering test VMs..."
          if command -v kcli &>/dev/null && [ -S /var/run/libvirt/libvirt-sock ]; then
            sudo kcli list vm 2>/dev/null | grep -iE "e2e|test|freeipa" | awk '{print $2}' | xargs -I {} sudo kcli delete vm {} -y 2>/dev/null || true
          fi

          echo "[OK] Cleanup complete"
          echo ""
          echo "Note: AI Assistant and Airflow are still running for debugging"
          echo "Run with teardown_first=true to fully reset"
