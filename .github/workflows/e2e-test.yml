# E2E Integration Test Workflow
# Per ADR-0067: Self-Hosted Runner E2E Testing with One-Shot Deployment
#
# This workflow deploys the complete Qubinode stack on a self-hosted runner
# and validates the Smart Pipeline (ADR-0066) with FreeIPA as test workload.
#
# IDEMPOTENT: Can be torn down and re-run cleanly

name: E2E Integration Test

on:
  schedule:
    - cron: '0 3 * * 0'  # Weekly Sunday 3am UTC
  workflow_dispatch:
    inputs:
      teardown_first:
        description: 'Teardown existing deployment before starting'
        type: boolean
        default: true
      deploy_freeipa:
        description: 'Deploy FreeIPA VM for full test'
        type: boolean
        default: true
      skip_cleanup:
        description: 'Skip cleanup after test (for debugging)'
        type: boolean
        default: false

env:
  # Deployment Configuration
  QUBINODE_DOMAIN: "e2e.qubinode.local"
  QUBINODE_ADMIN_USER: "admin"
  QUBINODE_CLUSTER_NAME: "e2e-test"
  QUBINODE_DEPLOYMENT_MODE: "production"
  QUBINODE_ENABLE_AI_ASSISTANT: "true"
  QUBINODE_ENABLE_AIRFLOW: "true"
  BUILD_AI_ASSISTANT_FROM_SOURCE: "true"
  CICD_PIPELINE: "true"
  INVENTORY: "localhost"
  # Skip local model (llama.cpp + Granite) - use cloud APIs via PydanticAI orchestrator
  # This speeds up CI by avoiding 2-5 min model download
  USE_LOCAL_MODEL: "false"

jobs:
  e2e-test:
    name: E2E Integration Test
    runs-on: self-hosted
    timeout-minutes: 120

    steps:
      # =========================================================================
      # Phase 0: Checkout and Setup
      # =========================================================================
      - name: Clean workspace (fix root-owned files from previous run)
        run: |
          # Previous runs with sudo -E create root-owned files that the runner can't clean
          # This must run BEFORE checkout to avoid permission errors
          if [ -d "${{ github.workspace }}" ]; then
            echo "[INFO] Cleaning workspace from previous run..."
            sudo rm -rf "${{ github.workspace }}"/* "${{ github.workspace }}"/.[!.]* 2>/dev/null || true
            echo "[OK] Workspace cleaned"
          fi

      - name: Checkout code
        uses: actions/checkout@v4

      - name: Display runner info
        run: |
          echo "========================================"
          echo "E2E Integration Test"
          echo "========================================"
          echo "Runner: $(hostname)"
          echo "OS: $(cat /etc/os-release | grep PRETTY_NAME | cut -d'"' -f2)"
          echo "Kernel: $(uname -r)"
          echo "Date: $(date)"
          echo "========================================"

      # =========================================================================
      # Phase 1: Teardown previous deployment (always runs for clean state)
      # =========================================================================
      - name: Teardown existing deployment
        run: |
          echo "========================================"
          echo "Tearing down existing deployment"
          echo "========================================"

          # Stop and remove ALL podman containers (both user and root)
          echo "[INFO] Stopping all podman containers..."
          podman stop -a 2>/dev/null || true
          podman rm -a -f 2>/dev/null || true
          sudo podman stop -a 2>/dev/null || true
          sudo podman rm -a -f 2>/dev/null || true

          # Clean up podman networks
          echo "[INFO] Cleaning up podman networks..."
          podman network prune -f 2>/dev/null || true
          sudo podman network prune -f 2>/dev/null || true

          # Stop Airflow systemd services if running
          if systemctl is-active --quiet airflow-scheduler 2>/dev/null; then
            echo "[INFO] Stopping Airflow services..."
            sudo systemctl stop airflow-scheduler airflow-webserver 2>/dev/null || true
          fi

          # Stop podman-compose services in airflow directory
          echo "[INFO] Stopping podman-compose services..."
          cd ${{ github.workspace }}/airflow 2>/dev/null && sudo podman-compose down 2>/dev/null || true

          # Delete FreeIPA VM if exists (only if kcli/libvirt available)
          if command -v kcli &>/dev/null && [ -S /var/run/libvirt/libvirt-sock ]; then
            echo "[INFO] Deleting FreeIPA VM..."
            kcli delete vm freeipa -y 2>/dev/null || true
            # Clean up any other test VMs
            echo "[INFO] Cleaning up test VMs..."
            kcli list vm 2>/dev/null | grep -E "e2e|test" | awk '{print $2}' | xargs -I {} kcli delete vm {} -y 2>/dev/null || true
          else
            echo "[INFO] Skipping VM cleanup (libvirt not available)"
          fi

          echo "[OK] Teardown complete"

      # =========================================================================
      # Phase 2: Deploy Infrastructure
      # =========================================================================
      - name: Login to Red Hat Registry
        env:
          REDHAT_USERNAME: ${{ secrets.REDHAT_USERNAME }}
          REDHAT_PASSWORD: ${{ secrets.REDHAT_PASSWORD }}
        run: |
          echo "[INFO] Logging into registry.redhat.io..."
          if [ -n "$REDHAT_USERNAME" ] && [ -n "$REDHAT_PASSWORD" ]; then
            # Login as root for privileged container builds
            sudo podman login registry.redhat.io -u "$REDHAT_USERNAME" -p "$REDHAT_PASSWORD"
            echo "[OK] Logged into Red Hat registry"
          else
            echo "[WARN] Red Hat registry credentials not configured, will use fallback image"
          fi

      - name: Setup Ansible vault password
        env:
          SSH_PASSWORD: ${{ secrets.SSH_PASSWORD }}
        run: |
          # Create vault password file for Ansible (referenced in ansible.cfg)
          VAULT_PASS="${SSH_PASSWORD:-defaultpassword}"
          echo "$VAULT_PASS" > "${{ github.workspace }}/.vault_password"
          chmod 600 "${{ github.workspace }}/.vault_password"
          # Also create in home directories for scripts that look there
          echo "$VAULT_PASS" > "$HOME/.vault_password"
          chmod 600 "$HOME/.vault_password"
          sudo sh -c "echo '$VAULT_PASS' > /root/.vault_password && chmod 600 /root/.vault_password"
          echo "[OK] Vault password files created"

      - name: Deploy Qubinode Stack
        env:
          SSH_PASSWORD: ${{ secrets.SSH_PASSWORD }}
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
          MANAGER_MODEL: ${{ secrets.MANAGER_MODEL }}
          DEVELOPER_MODEL: ${{ secrets.DEVELOPER_MODEL }}
          PYDANTICAI_MODEL: ${{ secrets.PYDANTICAI_MODEL }}
          QUBINODE_DOMAIN: ${{ env.QUBINODE_DOMAIN }}
          QUBINODE_ADMIN_USER: ${{ env.QUBINODE_ADMIN_USER }}
          QUBINODE_CLUSTER_NAME: ${{ env.QUBINODE_CLUSTER_NAME }}
          QUBINODE_DEPLOYMENT_MODE: ${{ env.QUBINODE_DEPLOYMENT_MODE }}
          QUBINODE_ENABLE_AI_ASSISTANT: ${{ env.QUBINODE_ENABLE_AI_ASSISTANT }}
          QUBINODE_ENABLE_AIRFLOW: ${{ env.QUBINODE_ENABLE_AIRFLOW }}
          BUILD_AI_ASSISTANT_FROM_SOURCE: ${{ env.BUILD_AI_ASSISTANT_FROM_SOURCE }}
          CICD_PIPELINE: ${{ env.CICD_PIPELINE }}
          INVENTORY: ${{ env.INVENTORY }}
        run: |
          echo "========================================"
          echo "Deploying Qubinode Stack"
          echo "========================================"

          # Create required directories with proper permissions
          sudo mkdir -p ai-assistant/data
          sudo chmod 777 ai-assistant/data

          # Run the one-shot deployment script as root with environment preserved
          cd ${{ github.workspace }}
          chmod +x scripts/development/deploy-qubinode.sh
          sudo -E ./scripts/development/deploy-qubinode.sh || {
            echo ""
            echo "========================================"
            echo "Deployment failed - checking container status"
            echo "========================================"
            sudo podman ps -a
            echo ""
            echo "Container logs:"
            sudo podman logs qubinode-ai-assistant 2>&1 | tail -100 || true
            exit 1
          }

          echo "[OK] Qubinode stack deployed"

      - name: Wait for services to be ready
        run: |
          echo "========================================"
          echo "Waiting for services to be ready"
          echo "========================================"

          # AI Assistant model download can take 2-5 minutes
          # Use podman health status instead of just curl
          MAX_WAIT=360  # 6 minutes
          CHECK_INTERVAL=5
          ELAPSED=0

          echo "[INFO] Waiting for AI Assistant (model download may take 2-5 minutes)..."

          while [ $ELAPSED -lt $MAX_WAIT ]; do
            # Check if container is still running
            if ! sudo podman ps --format "{{.Names}}" 2>/dev/null | grep -q "^qubinode-ai-assistant$"; then
              echo "[ERROR] Container stopped running"
              sudo podman logs qubinode-ai-assistant 2>&1 | tail -50 || true
              exit 1
            fi

            # Get container health status via podman inspect
            HEALTH_STATUS=$(sudo podman inspect --format='{{.State.Health.Status}}' qubinode-ai-assistant 2>/dev/null || echo "unknown")

            case "$HEALTH_STATUS" in
              "healthy")
                echo "[OK] Container health check passed after ${ELAPSED}s"
                # Verify orchestrator endpoint
                ORCH_STATUS=$(curl -s http://localhost:8080/orchestrator/status 2>/dev/null || echo '{}')
                if echo "$ORCH_STATUS" | grep -q '"available"'; then
                  echo "[OK] Orchestrator is available"
                  echo "$ORCH_STATUS" | jq -c '{available, api_keys: .api_keys_configured}' 2>/dev/null || true
                  break 2  # Exit both case and while
                else
                  echo "[WARN] Health OK but orchestrator not available - checking logs..."
                  sudo podman logs qubinode-ai-assistant 2>&1 | grep -v "GET /\|POST /" | tail -20 || true
                fi
                ;;
              "starting")
                # Show progress every 30 seconds
                if [ $((ELAPSED % 30)) -eq 0 ] && [ $ELAPSED -gt 0 ]; then
                  echo "[INFO] Container starting... (${ELAPSED}s elapsed)"
                  sudo podman logs qubinode-ai-assistant 2>&1 | grep -i "download progress\|downloading" | tail -1 || true
                fi
                ;;
              "unhealthy")
                echo "[ERROR] Container health check failed"
                sudo podman logs qubinode-ai-assistant 2>&1 | tail -100 || true
                exit 1
                ;;
              *)
                # No health status yet - try endpoint directly
                HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:8080/health 2>/dev/null || echo "000")
                if [ "$HTTP_CODE" = "200" ]; then
                  echo "[OK] Health endpoint responding (HTTP 200)"
                  ORCH_STATUS=$(curl -s http://localhost:8080/orchestrator/status 2>/dev/null || echo '{}')
                  if echo "$ORCH_STATUS" | grep -q '"available"'; then
                    echo "[OK] Orchestrator ready"
                    break 2
                  fi
                fi
                ;;
            esac

            sleep $CHECK_INTERVAL
            ELAPSED=$((ELAPSED + CHECK_INTERVAL))
          done

          # Check if we exited the loop due to timeout
          if [ $ELAPSED -ge $MAX_WAIT ]; then
            echo ""
            echo "[ERROR] AI Assistant failed to start after ${MAX_WAIT}s"
            echo ""
            echo "=== CONTAINER STATUS ==="
            sudo podman inspect --format='Status: {{.State.Status}}, Health: {{.State.Health.Status}}' qubinode-ai-assistant 2>/dev/null || true
            echo ""
            echo "=== ERROR LOGS ==="
            sudo podman logs qubinode-ai-assistant 2>&1 | grep -iE "(error|exception|traceback|failed|cannot)" | head -30 || true
            echo ""
            echo "=== FULL STARTUP LOGS ==="
            sudo podman logs qubinode-ai-assistant 2>&1 | grep -v "GET /\|POST /" | head -100 || true
            exit 1
          fi

          # Wait for Airflow
          echo ""
          echo "[INFO] Waiting for Airflow..."
          for i in {1..30}; do
            if curl -s http://localhost:8888/health | grep -q "healthy"; then
              echo "[OK] Airflow is ready"
              break
            fi
            echo "  Attempt $i/30..."
            sleep 10
          done

          echo ""
          echo "[OK] All services ready"

      # =========================================================================
      # Phase 3: Validate Services (before FreeIPA deployment)
      # =========================================================================
      - name: Validate AI Assistant
        run: |
          echo "========================================"
          echo "Validating AI Assistant"
          echo "========================================"

          # Health check
          echo "[INFO] Health check..."
          curl -s http://localhost:8080/health | jq . || curl -s http://localhost:8080/health

          # Check models configured
          echo ""
          echo "[INFO] Model configuration..."
          curl -s http://localhost:8080/models 2>/dev/null | jq . || echo "Models endpoint not available"

          echo ""
          echo "[OK] AI Assistant validation complete"

      - name: Validate Airflow DAGs
        run: |
          echo "========================================"
          echo "Validating Airflow DAGs"
          echo "========================================"

          # List DAGs via podman exec (airflow CLI is inside the container)
          echo "[INFO] Available DAGs:"
          sudo podman exec airflow-scheduler airflow dags list 2>/dev/null || {
            # Fallback: Use the AI Assistant's orchestrator which has DAG discovery
            echo "[INFO] Using AI Assistant orchestrator for DAG list..."
            curl -s http://localhost:8080/orchestrator/dags | jq -r '.dags[].dag_id // .dags[]' 2>/dev/null || echo "Could not list DAGs"
          }

          # Check for import errors via podman exec
          echo ""
          echo "[INFO] DAG import errors:"
          sudo podman exec airflow-scheduler airflow dags list-import-errors 2>/dev/null || echo "[INFO] Import errors check skipped (scheduler not ready)"

          echo ""
          echo "[OK] Airflow validation complete"

      # =========================================================================
      # Phase 4: Deploy FreeIPA VM via PydanticAI Smart Pipeline (ADR-0066)
      # =========================================================================
      - name: Deploy FreeIPA via AI Assistant Orchestrator
        if: ${{ github.event.inputs.deploy_freeipa == 'true' || github.event_name == 'schedule' }}
        run: |
          echo "========================================"
          echo "Deploying FreeIPA via PydanticAI Smart Pipeline"
          echo "========================================"

          # Check if FreeIPA already exists
          if kcli info vm freeipa 2>/dev/null | grep -q "status: up"; then
            echo "[OK] FreeIPA VM already running"
            kcli info vm freeipa
            exit 0
          fi

          # Verify AI Assistant orchestrator is available and properly configured
          echo "[INFO] Checking AI Assistant Orchestrator status..."
          ORCHESTRATOR_STATUS=$(curl -s http://localhost:8080/orchestrator/status 2>/dev/null)
          echo "$ORCHESTRATOR_STATUS" | jq . 2>/dev/null || echo "$ORCHESTRATOR_STATUS"

          if ! echo "$ORCHESTRATOR_STATUS" | jq -e '.available == true' &>/dev/null; then
            echo "[ERROR] AI Assistant Orchestrator not available"
            echo "[INFO] The PydanticAI orchestrator is required for intent-based deployments (ADR-0066)"
            exit 1
          fi
          echo "[OK] Orchestrator is available"

          # Check if API keys are configured
          API_KEYS_OK=$(echo "$ORCHESTRATOR_STATUS" | jq -r '.api_keys_configured | to_entries | map(select(.value == true)) | length')
          if [ "$API_KEYS_OK" = "0" ]; then
            echo "[ERROR] No AI API keys configured in orchestrator"
            echo "[INFO] Ensure OPENROUTER_API_KEY is passed to the AI Assistant container"
            echo "[INFO] Check: api_keys_configured shows all false"
            exit 1
          fi
          echo "[OK] API keys configured: $API_KEYS_OK provider(s)"

          # Check DAG discovery
          echo "[INFO] Checking DAG discovery..."
          DAGS_COUNT=$(curl -s http://localhost:8080/orchestrator/dags | jq '.total')
          if [ "$DAGS_COUNT" = "0" ] || [ -z "$DAGS_COUNT" ]; then
            echo "[ERROR] No DAGs discovered by orchestrator"
            echo "[INFO] Ensure airflow/dags is mounted at /app/airflow/dags in the container"
            exit 1
          fi
          echo "[OK] Discovered $DAGS_COUNT DAGs"

          # Trigger FreeIPA deployment via AI Assistant Orchestrator (ADR-0066)
          # Using /orchestrator/intent endpoint for intent-based execution:
          # 1. Analyze the intent with PydanticAI Manager Agent
          # 2. Find/validate the appropriate DAG (freeipa_deployment)
          # 3. Execute via Airflow
          # 4. Monitor for shadow errors
          echo ""
          echo "[INFO] Sending request to AI Assistant Orchestrator..."
          echo "[INFO] Using /orchestrator/intent endpoint (intent-based execution)"

          RESPONSE=$(curl -s -X POST http://localhost:8080/orchestrator/intent \
            -H "Content-Type: application/json" \
            -d '{
              "intent": "Deploy FreeIPA server for E2E testing",
              "params": {
                "vm_name": "freeipa",
                "action": "create"
              },
              "auto_approve": true,
              "auto_execute": true
            }')

          echo ""
          echo "Orchestrator Response:"
          echo "$RESPONSE" | jq . 2>/dev/null || echo "$RESPONSE"

          # Check for HTTP errors
          if echo "$RESPONSE" | jq -e '.detail' &>/dev/null; then
            echo ""
            echo "[ERROR] Orchestrator returned an error:"
            echo "$RESPONSE" | jq '.detail' 2>/dev/null
            exit 1
          fi

          # Extract flow_id for monitoring
          FLOW_ID=$(echo "$RESPONSE" | jq -r '.flow_id // empty')
          if [ -n "$FLOW_ID" ]; then
            echo ""
            echo "[INFO] Flow ID: $FLOW_ID"
            echo "[INFO] Status endpoint: /orchestrator/flows/$FLOW_ID/status"
          fi

          # Check execution status
          STATUS=$(echo "$RESPONSE" | jq -r '.status // empty')
          DAG_ID=$(echo "$RESPONSE" | jq -r '.dag_id // empty')

          echo ""
          echo "[INFO] Status: $STATUS"
          echo "[INFO] DAG ID: $DAG_ID"

          if [ "$STATUS" = "executing" ] || [ "$STATUS" = "in_progress" ]; then
            echo "[OK] FreeIPA deployment initiated via Smart Pipeline"
          elif [ "$STATUS" = "completed" ] || [ "$STATUS" = "success" ]; then
            echo "[OK] FreeIPA deployment completed"
          elif [ "$STATUS" = "failed" ]; then
            echo ""
            echo "[ERROR] Orchestrator returned failure:"
            echo "$RESPONSE" | jq '.error_message' 2>/dev/null
            echo ""
            echo "User Actions:"
            echo "$RESPONSE" | jq '.user_actions' 2>/dev/null
            echo ""
            echo "Escalation Context:"
            echo "$RESPONSE" | jq '.escalation_context' 2>/dev/null
            exit 1
          else
            echo "[WARN] Unexpected orchestrator status: $STATUS"
            # Don't fail - let the validation step check if FreeIPA actually deployed
          fi

      - name: Wait for FreeIPA to be ready
        if: ${{ github.event.inputs.deploy_freeipa == 'true' || github.event_name == 'schedule' }}
        run: |
          echo "========================================"
          echo "Waiting for FreeIPA VM"
          echo "========================================"

          MAX_ATTEMPTS=60
          ATTEMPT=0

          while [ $ATTEMPT -lt $MAX_ATTEMPTS ]; do
            ATTEMPT=$((ATTEMPT + 1))
            echo "Check $ATTEMPT/$MAX_ATTEMPTS..."

            # Get FreeIPA IP
            FREEIPA_IP=$(kcli info vm freeipa 2>/dev/null | grep 'ip:' | awk '{print $2}' | head -1)

            if [ -n "$FREEIPA_IP" ] && [ "$FREEIPA_IP" != "None" ]; then
              echo "[INFO] FreeIPA IP: $FREEIPA_IP"

              # Check if FreeIPA web UI is accessible
              if curl -sk --connect-timeout 5 "https://$FREEIPA_IP/ipa/ui/" | grep -q "IPA"; then
                echo ""
                echo "========================================"
                echo "[OK] FreeIPA is ready!"
                echo "========================================"
                echo "IP Address: $FREEIPA_IP"
                echo "Web UI: https://$FREEIPA_IP/ipa/ui/"
                echo "========================================"
                exit 0
              fi

              # Alternative: check SSH
              if nc -z -w5 "$FREEIPA_IP" 22 2>/dev/null; then
                echo "[INFO] FreeIPA SSH is accessible, checking services..."
                ssh -o StrictHostKeyChecking=no -o ConnectTimeout=5 root@$FREEIPA_IP \
                  "systemctl is-active ipa" 2>/dev/null && {
                    echo "[OK] FreeIPA IPA service is running"
                    exit 0
                  }
              fi
            fi

            sleep 30
          done

          echo "[WARN] FreeIPA may still be provisioning"
          kcli info vm freeipa 2>/dev/null || true

      # =========================================================================
      # Phase 5: Validate FreeIPA Deployment
      # =========================================================================
      - name: Validate FreeIPA VM
        if: ${{ github.event.inputs.deploy_freeipa == 'true' || github.event_name == 'schedule' }}
        run: |
          echo "========================================"
          echo "Validating FreeIPA VM"
          echo "========================================"

          # Get VM info
          echo "[INFO] VM Status:"
          kcli info vm freeipa 2>/dev/null || echo "FreeIPA VM not found"

          # Get IP
          FREEIPA_IP=$(kcli info vm freeipa 2>/dev/null | grep 'ip:' | awk '{print $2}' | head -1)

          if [ -n "$FREEIPA_IP" ] && [ "$FREEIPA_IP" != "None" ]; then
            echo ""
            echo "[INFO] FreeIPA IP: $FREEIPA_IP"

            # Test DNS resolution
            echo ""
            echo "[INFO] Testing DNS..."
            dig @$FREEIPA_IP freeipa.${QUBINODE_DOMAIN} +short 2>/dev/null || echo "DNS query failed"

            # Test LDAP
            echo ""
            echo "[INFO] Testing LDAP port..."
            nc -z -w5 $FREEIPA_IP 389 && echo "[OK] LDAP port open" || echo "[WARN] LDAP port not accessible"

            # Test Kerberos
            echo ""
            echo "[INFO] Testing Kerberos port..."
            nc -z -w5 $FREEIPA_IP 88 && echo "[OK] Kerberos port open" || echo "[WARN] Kerberos port not accessible"
          fi

          echo ""
          echo "[OK] FreeIPA validation complete"

      # =========================================================================
      # Phase 6: Smart Pipeline Validation (ADR-0066)
      # =========================================================================
      - name: Check Shadow Errors
        continue-on-error: true
        run: |
          echo "========================================"
          echo "Checking Smart Pipeline Shadow Errors"
          echo "========================================"

          # Query shadow errors endpoint
          ERRORS=$(curl -s http://localhost:8080/orchestrator/shadow-errors 2>/dev/null || echo '{"error": "endpoint not available"}')

          echo "$ERRORS" | jq . 2>/dev/null || echo "$ERRORS"

          # Check if there are shadow failures
          if echo "$ERRORS" | jq -e '.total_shadow_failures > 0' 2>/dev/null; then
            echo ""
            echo "[WARN] Shadow errors detected - review above"
          else
            echo ""
            echo "[OK] No shadow errors detected"
          fi

      - name: Check OpenLineage/Marquez
        continue-on-error: true
        run: |
          echo "========================================"
          echo "Checking OpenLineage/Marquez"
          echo "========================================"

          # Check if Marquez is running
          if curl -s http://localhost:5001/api/v1/namespaces 2>/dev/null | jq . ; then
            echo ""
            echo "[OK] Marquez is accessible"

            # List jobs in qubinode namespace
            echo ""
            echo "[INFO] Jobs in qubinode namespace:"
            curl -s http://localhost:5001/api/v1/namespaces/qubinode/jobs 2>/dev/null | jq '.jobs[].name' 2>/dev/null || echo "No jobs found"
          else
            echo "[INFO] Marquez not running or not accessible"
          fi

      # =========================================================================
      # Phase 7: Summary
      # =========================================================================
      - name: Generate Test Summary
        run: |
          echo ""
          echo "========================================"
          echo "E2E Test Summary"
          echo "========================================"
          echo ""
          echo "Deployment Status:"
          echo "  - AI Assistant: $(curl -s http://localhost:8080/health | grep -q 'ok\|healthy' && echo '✅ Running' || echo '❌ Not running')"
          echo "  - Airflow: $(curl -s http://localhost:8888/health | grep -q 'healthy' && echo '✅ Running' || echo '❌ Not running')"

          FREEIPA_IP=$(kcli info vm freeipa 2>/dev/null | grep 'ip:' | awk '{print $2}' | head -1)
          if [ -n "$FREEIPA_IP" ] && [ "$FREEIPA_IP" != "None" ]; then
            echo "  - FreeIPA VM: ✅ Running ($FREEIPA_IP)"
          else
            echo "  - FreeIPA VM: ❌ Not deployed or no IP"
          fi

          echo ""
          echo "Access URLs:"
          echo "  - AI Assistant: http://$(hostname):8080"
          echo "  - Airflow UI: http://$(hostname):8888"
          if [ -n "$FREEIPA_IP" ]; then
            echo "  - FreeIPA: https://$FREEIPA_IP"
          fi
          echo ""
          echo "========================================"

      # =========================================================================
      # Phase 8: Cleanup (optional)
      # =========================================================================
      - name: Cleanup test resources
        if: ${{ always() && github.event.inputs.skip_cleanup != 'true' && github.event_name == 'schedule' }}
        run: |
          echo "========================================"
          echo "Cleaning up test resources"
          echo "========================================"

          # Only cleanup VMs on scheduled runs, keep services running
          echo "[INFO] Deleting FreeIPA VM..."
          kcli delete vm freeipa -y 2>/dev/null || true

          echo "[OK] Cleanup complete"
          echo ""
          echo "Note: AI Assistant and Airflow are still running for debugging"
          echo "Run with teardown_first=true to fully reset"
