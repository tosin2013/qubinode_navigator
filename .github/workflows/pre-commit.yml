# =============================================================================
# Pre-commit CI Workflow
# =============================================================================
# Runs pre-commit hooks on all files for comprehensive code quality checks.
#
# Includes:
# - Gitleaks (secret detection)
# - Ruff (Python linting & formatting)
# - pylint-airflow (Airflow DAG checks)
# - airflint (Airflow best practices)
# - ShellCheck (Shell script linting)
# - YAML/JSON validation
# - Custom Qubinode DAG linting (ADR-0045/ADR-0046)
#
# =============================================================================

name: Pre-commit

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  workflow_dispatch:

jobs:
  pre-commit:
    name: Pre-commit Checks
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install pre-commit
        run: |
          pip install pre-commit
          pip install pylint pylint-airflow apache-airflow==2.10.4

      - name: Run pre-commit
        uses: pre-commit/action@v3.0.1
        with:
          extra_args: --all-files --show-diff-on-failure

  # Separate job for Gitleaks with better reporting
  # Uses free gitleaks CLI instead of paid gitleaks-action (which requires license for orgs)
  gitleaks:
    name: Secret Detection (Gitleaks)
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for better detection

      - name: Install Gitleaks
        run: |
          # Install latest gitleaks from GitHub releases
          GITLEAKS_VERSION=$(curl -s https://api.github.com/repos/gitleaks/gitleaks/releases/latest | grep '"tag_name"' | sed -E 's/.*"v([^"]+)".*/\1/')
          curl -sSfL "https://github.com/gitleaks/gitleaks/releases/download/v${GITLEAKS_VERSION}/gitleaks_${GITLEAKS_VERSION}_linux_x64.tar.gz" | tar -xz
          sudo mv gitleaks /usr/local/bin/
          gitleaks version

      - name: Run Gitleaks
        run: |
          echo "========================================"
          echo "Running Gitleaks Secret Detection"
          echo "========================================"

          # Run gitleaks with config to reduce false positives
          gitleaks detect --source . --config .gitleaks.toml --redact --no-git || {
            echo ""
            echo "[WARN] Potential secrets detected - review output above"
            echo "If these are false positives, update .gitleaks.toml allowlist"
            exit 1
          }

          echo ""
          echo "[OK] No secrets detected"

  # Separate job for comprehensive Airflow linting
  airflow-lint:
    name: Airflow DAG Linting
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          pip install apache-airflow==2.10.4
          pip install apache-airflow-providers-postgres
          pip install pylint pylint-airflow airflint
          pip install pyyaml

      - name: Run Qubinode DAG linter
        run: |
          chmod +x airflow/scripts/lint-dags.sh
          ./airflow/scripts/lint-dags.sh airflow/dags/

      - name: Run pylint-airflow
        continue-on-error: true  # Don't fail on warnings
        run: |
          echo "========================================"
          echo "pylint-airflow Analysis"
          echo "========================================"

          # Run pylint with airflow plugin on DAG files
          for dag in airflow/dags/*.py; do
            filename=$(basename "$dag")

            # Skip non-DAG files
            [[ "$filename" == dag_helpers.py ]] && continue
            [[ "$filename" == dag_factory.py ]] && continue
            [[ "$filename" == dag_loader.py ]] && continue
            [[ "$filename" == dag_logging_mixin.py ]] && continue

            echo ""
            echo "Checking: $filename"
            pylint --load-plugins=pylint_airflow \
              --disable=all \
              --enable=C83,R83,W83,E83 \
              "$dag" 2>/dev/null || true
          done

          echo ""
          echo "[OK] pylint-airflow analysis complete"

      - name: Run airflint
        continue-on-error: true  # Don't fail on suggestions
        run: |
          echo "========================================"
          echo "airflint Best Practices Analysis"
          echo "========================================"

          airflint airflow/dags/ 2>/dev/null || true

          echo ""
          echo "[OK] airflint analysis complete"

      - name: Validate DAG imports
        run: |
          echo "========================================"
          echo "Validating DAG Imports"
          echo "========================================"

          export AIRFLOW_HOME=$(pwd)/airflow
          export AIRFLOW__CORE__DAGS_FOLDER=$(pwd)/airflow/dags
          export AIRFLOW__CORE__LOAD_EXAMPLES=false
          export AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=sqlite:///$(pwd)/airflow/airflow.db

          cd airflow

          # Initialize Airflow DB (use python -m to ensure correct path)
          # Allow migrate to fail initially (may need to init first on fresh install)
          echo "Initializing Airflow database..."
          python -m airflow db migrate 2>&1 || {
            echo "[WARN] db migrate failed, trying db init..."
            python -m airflow db init 2>&1 || true
          }

          # List DAGs and check for import errors (auto-confirm with yes)
          echo "Listing DAGs..."
          yes | python -m airflow dags list 2>&1 | tee dag_list.txt || true

          # List DAGs and check for import errors
          set +o pipefail  # Allow pipe to continue even if grep finds nothing
          python -m airflow dags list 2>&1 | tee dag_list.txt
          airflow_exit_code=${PIPESTATUS[0]}

          # Check for actual import errors (more specific patterns)
          # Exclude false positives like "No data found", "No errors found", etc.
          error_lines=$(grep -iE "(import error|traceback|failed to import|syntax error|indentation error|module.*not found|cannot import)" dag_list.txt | grep -vE "(No data found|No errors found|No DAGs found)" || true)

          if [ -n "$error_lines" ]; then
            echo "[ERROR] DAG import errors detected:"
            echo "$error_lines"
            cat dag_list.txt
            exit 1
          fi

          # Also check exit code of airflow dags list
          if [ "$airflow_exit_code" -ne 0 ]; then
            echo "[ERROR] airflow dags list command failed with exit code $airflow_exit_code"
            cat dag_list.txt
            exit 1
          fi

          echo ""
          echo "[OK] All DAGs imported successfully"
