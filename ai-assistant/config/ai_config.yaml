# Qubinode AI Assistant Configuration
# Based on ADR-0027: CPU-Based AI Deployment Assistant Architecture

ai:
  model_name: "granite-4.0-micro"
  model_path: "/app/models/granite-4.0-micro.gguf"
  max_tokens: 512
  temperature: 0.7
  context_size: 2048
  threads: 4  # Will be overridden by CPU count

server:
  host: "0.0.0.0"
  port: 8080
  llama_server_port: 8081
  log_level: "INFO"
  timeout: 30

features:
  diagnostics: true
  system_monitoring: true
  log_analysis: true
  rag_enabled: true

security:
  enable_auth: false
  api_key: null
  allowed_hosts: ["*"]
  rate_limit: 100

storage:
  models_dir: "/app/models"
  data_dir: "/app/data"
  logs_dir: "/app/logs"
  vector_db_path: "/app/data/chromadb"

qubinode:
  integration_enabled: true
  plugin_framework_path: "/opt/qubinode/core"
  ansible_callback: true
  setup_hooks: true

# Logging configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "/app/logs/ai-assistant.log"
  max_size_mb: 100
  backup_count: 5
